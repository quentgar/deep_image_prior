# -*- coding: utf-8 -*-
"""load_video_images.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16I3Giqlru_5NrrjNZXeHSnAOre0YT4fF
"""

!git clone https://github.com/quentgar/dip-inpainting-registration.git
!mv dip-inpainting-registration/* ./

!git clone https://github.com/DmitryUlyanov/deep-image-prior
!mv deep-image-prior/* ./

pip install voxelmorph

# Commented out IPython magic to ensure Python compatibility.
from __future__ import print_function
import matplotlib.pyplot as plt
# %matplotlib inline

import os
# os.environ['CUDA_VISIBLE_DEVICES'] = '1'

import numpy as np
from models.skip import skip
from src.hourglass_network import *
import torch
import torch.optim

from utils.inpainting_utils import *
from skimage.measure import compare_psnr

from voxelmorph.torch.layers import SpatialTransformer
import seaborn as sns

torch.backends.cudnn.enabled = True
torch.backends.cudnn.benchmark =True
dtype = torch.cuda.FloatTensor

PLOT = True
imsize = -1
dim_div_by = 32

img_path = 'mydata/video/subsea01/frames/01_0000'
mask_path = 'mydata/video/subsea01/mask/01_0000'

ind_debut = 150
ind_fin = 169

size = img_np1.shape[1:]

def optimize_perso(optimizer_type, parameters1, parameters2, closure, LR, num_iter, ind_iter):
    print('Starting optimization with ADAM')
    optimizer_inpainting = torch.optim.Adam(parameters1, lr=LR)
    optimizer_recalage = torch.optim.Adam(parameters2, lr=LR)

    iter = num_iter // ind_iter
    
    for j in range(iter):
        for i in range(ind_iter):
          # Optimiser paramètres inpainting
          optimizer_inpainting.zero_grad()
          closure()
          optimizer_inpainting.step()

        for i in range(ind_iter):
          # Optimiser paramètres recalage
          optimizer_recalage.zero_grad()
          closure()
          optimizer_recalage.step()

"""# Inpainting sur la première image"""

def format_image(img_path, mask_path, imsize, dim_div_by):
  img_pil, img_np = get_image(img_path, imsize)
  img_mask_pil, img_mask_np = get_image(mask_path, imsize)
  img_pil = crop_image(img_pil, dim_div_by)
  img_mask_pil = crop_image(img_mask_pil, dim_div_by)
  img_np = pil_to_np(img_pil)
  img_mask_np = 1 - pil_to_np(img_mask_pil)

  return img_np, img_mask_np

img_path1 = img_path + str(ind_debut) + '.png'
mask_path1 = mask_path + str(ind_debut) + '.png'
img_np1, mask_np1 = format_image(img_path1, mask_path1, imsize, dim_div_by)

"""## Création du réseau"""

pad = 'reflection' # 'zero'
OPT_OVER = 'net'
OPTIMIZER = 'adam'

INPUT = 'noise'
input_depth = 32
LR = 0.01 
num_iter = 3000
param_noise = False
show_every = 50
figsize = 5
reg_noise_std = 0.03
depth = 5


net = build_hourglass(input_depth, output_depth=img_np1.shape[0], 
               num_channels_down = [128]*depth,
               num_channels_up =   [128]*depth,
               num_channels_skip =    [0]*depth,  
               filter_size_up = 5, filter_size_down = 5, 
               up_samp_mode='nearest', filter_skip_size=1,num_scales=depth).type(dtype)

net_input = get_noise(input_depth, INPUT, img_np1.shape[1:]).type(dtype)

# Loss
mse = torch.nn.MSELoss().type(dtype)

img_var1 = np_to_torch(img_np1).type(dtype)
mask_var1 = np_to_torch(mask_np1).type(dtype)

i = 0
list_iter = []
list_psnr = []
list_loss = []

def closure_inp():
    
    global i, list_iter, list_psnr, list_loss
    
    if param_noise:
        for n in [x for x in net.parameters() if len(x.size()) == 4]:
            n = n + n.detach().clone().normal_() * n.std() / 50
    
    net_input = net_input_saved
    if reg_noise_std > 0:
        net_input = net_input_saved + (noise.normal_() * reg_noise_std)
        
        
    out = net(net_input)
   
    total_loss = mse(out * mask_var1, img_var1 * mask_var1)
    total_loss.backward()
        
    if PLOT and i % show_every == 0:
        print ('Iteration %05d    Loss %f' % (i, total_loss.item()), '\r', end='')
        
        out_np = torch_to_np(out)
        list_iter.append(i)
        #list_psnr.append(compare_psnr(img_np1,out_np))
        list_loss.append(total_loss.item())
        #plt.imshow(out_np.transpose(1,2,0))
        #plt.show()
        #plot_image_grid([np.clip(out_np, 0, 1)], factor=figsize, nrow=1)
        
    i += 1

    return total_loss

net_input_saved = net_input.detach().clone()
noise = net_input.detach().clone()

p = get_params(OPT_OVER, net, net_input)
optimize(OPTIMIZER, p, closure_inp, LR, num_iter)

res1 = torch_to_np(net(net_input))
plt.figure()
plt.imshow(res1.transpose(1,2,0))
plt.axis('off')
plt.savefig('res'+str(ind_debut)+'.png', dpi=300, bbox_inches='tight')

img_prec_var = net(net_input).detach().clone()
num_iter = 1500
LR = 0.001

for j in range(ind_debut+1, ind_fin+1):

  # Masque et image 2
  img2_path = img_path + str(j) + '.png'
  mask2_path = mask_path + str(j) + '.png'

  img_np2, mask_np2 = format_image(img_2_path, mask2_path, imsize, dim_div_by)

  # Création des réseaux 
  net_recalage = build_hourglass(input_depth, output_depth=2, 
            num_channels_down = [128]*depth,
            num_channels_up =   [128]*depth,
            num_channels_skip =    [4]*depth,  
            filter_size_up = 3, filter_size_down = 3, 
            up_samp_mode='nearest', filter_skip_size=1,num_scales=depth,need_sigmoid=False).type(dtype)

  net_inpainting = build_hourglass(input_depth, output_depth=img_np1.shape[0], 
               num_channels_down = [128]*depth,
               num_channels_up =   [128]*depth,
               num_channels_skip =    [0]*depth,  
               filter_size_up = 5, filter_size_down = 5, 
               up_samp_mode='nearest', filter_skip_size=1,num_scales=depth).type(dtype)

  net_input = get_noise(input_depth, INPUT, img_np1.shape[1:]).type(dtype)
  #net_input.div_(10)

  # Spatial transformer
  transformer = SpatialTransformer(size)

  # Création des tenseurs

  img_var2 = np_to_torch(img_np2).type(dtype)
  mask_var2 = np_to_torch(img_mask2_np).type(dtype)

  i = 0
  list_iter = []
  list_loss = []

  best_loss = 10
  best_iter = 0
  best_out = None
  best_flow = None

  l1 = 1
  l2 = 1

  def closure():
      
      global i, list_iter, list_loss, inp_prec, flow_prec, best_loss, best_iter, best_out, best_flow
      
      if param_noise:
          for n in [x for x in net_inpainting.parameters() if len(x.size()) == 4]:
              n = n + n.detach().clone().normal_() * n.std() / 50
          for n in [x for x in net_recalage.parameters() if len(x.size()) == 4]:
              n = n + n.detach().clone().normal_() * n.std() / 50
      
      net_input = net_input_saved

      if reg_noise_std > 0:
          net_input = net_input_saved + (noise.normal_() * reg_noise_std)

      inp_prec = net_inpainting(net_input)
      flow_prec = net_recalage(net_input)
      
      out_trans = transformer(img_prec_var.type(torch.FloatTensor),flow_prec.type(torch.FloatTensor)).type(dtype)
    
      total_loss = l1*mse(out_trans, inp_prec) + l2*mse(inp_prec * mask_var2, img_var2 * mask_var2)
      total_loss.backward()

      if total_loss.item() < best_loss:
        best_loss = total_loss.item()
        best_iter = i
        best_out_trans = out_trans
        best_out_inp = inp_prec
        best_flow = flow_prec
          
      if PLOT and i % show_every == 0:
          print ('Iteration %05d    Loss %f' % (i, total_loss.item()), '\r', end='')
          
          list_iter.append(i)
          list_loss.append(total_loss.item())
          #plt.imshow(out_np.transpose(1,2,0))
          #plt.show()
          plot_image_grid([np.clip(torch_to_np(out_trans), 0, 1), np.clip(torch_to_np(inp_prec), 0, 1)], factor=5, nrow=2)
          
      i += 1

      return total_loss

  net_input = get_noise(input_depth, INPUT, img_np1.shape[1:]).type(dtype)

  net_input_saved = net_input.detach().clone()
  noise = net_input.detach().clone()

  p1 = get_params(OPT_OVER, net_inpainting, net_input)
  p2 = get_params(OPT_OVER, net_recalage, net_input)

  ind_iter = 1

  optimize_perso(OPTIMIZER, p1, p2, closure, LR, num_iter, ind_iter)

  img_prec_var = net_inpainting(net_input).detach().clone()
  img_np = torch_to_np(img_prec_var)

  plt.figure()
  plt.imshow(img_np.transpose(1,2,0))
  plt.axis('off')
  plt.savefig('res'+str(j)+'.png', dpi=300, bbox_inches='tight')
